{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dd0625",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Python 3.8, PyTorch 1.7, and Transformers 4.3/4.4.\n",
    "# !pip install --upgrade pip\n",
    "# !pip install -qU torch==1.7.1\n",
    "!pip install -q transformers==4.6.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorboard==2.5.0 tensorflow==2.5.0 tensorflow-datasets==4.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f747b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/kzinmr/cuad.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e03ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd cuad && mkdir data && cp data.zip data/ && cd data && unzip ./data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd cuad && mkdir -p ./train_models/roberta-base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505f727",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e77a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "cache_dir = ''\n",
    "model_name_or_path = 'roberta-base'\n",
    "max_seq_length=512\n",
    "evaluate = False\n",
    "subset_cached_features_file = os.path.join(\n",
    "    cache_dir,\n",
    "    \"balanced_subset_cached_{}_{}_{}\".format(\n",
    "        \"dev\" if evaluate else \"train\",\n",
    "        list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "        str(max_seq_length),\n",
    "    ),\n",
    ")\n",
    "dataset = torch.load(subset_cached_features_file)[\"dataset\"]\n",
    "features, examples = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForQuestionAnswering,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "\n",
    "cache_dir=None\n",
    "model_name_or_path = 'roberta-base'\n",
    "config_name = model_name_or_path\n",
    "config = AutoConfig.from_pretrained(\n",
    "    config_name,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=cache_dir,\n",
    ")\n",
    "# model.to(device)\n",
    "tokenizer_name = model_name_or_path\n",
    "do_lower_case=False\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_name,\n",
    "    do_lower_case=do_lower_case,\n",
    "    cache_dir=cache_dir,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "cache_dir = ''\n",
    "# model_name_or_path = 'roberta-base'\n",
    "max_seq_length=512\n",
    "subset_cached_features_file = os.path.join(\n",
    "    cache_dir,\n",
    "    \"balanced_subset_cached_{}_{}_{}\".format(\n",
    "        \"dev\" if evaluate else \"train\",\n",
    "        list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "        str(max_seq_length),\n",
    "    ),\n",
    ")\n",
    "train_dataset = torch.load(subset_cached_features_file)[\"dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16b9ccd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from train import build_args, train\n",
    "args = build_args(notebook=True)\n",
    "args.device = 'gpu'\n",
    "global_step, tr_loss = train(args, train_dataset, model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad98678d",
   "metadata": {},
   "source": [
    "# CUAD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966937b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def filter_data(data, targets=['Parties']):\n",
    "    for d in data:\n",
    "        for p in d['paragraphs']:\n",
    "            p['qas'] = [qa for qa in p['qas'] if any(target in qa['question'] for target in targets)]\n",
    "\n",
    "# SquadV2Processor.get_train_examples を以下の絞り込みするように書き換える\n",
    "with open('./data/train_separate_questions.json') as reader:\n",
    "    js = json.load(reader)\n",
    "    print(js.keys())\n",
    "    data = js[\"data\"]\n",
    "    version = js['version']\n",
    "    print(sum(len(p['qas']) for d in data for p in d['paragraphs']))\n",
    "    filter_data(data, targets=['Parties'])\n",
    "    print(sum(len(p['qas']) for d in data for p in d['paragraphs']))\n",
    "\n",
    "with open('./data/train_separate_questions_parties.json', 'w') as writer:\n",
    "    j = json.dumps({'data': data, 'version': version})\n",
    "    writer.write(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00984397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !cd cuad && ./run.sh\n",
    "!python train.py --output_dir ./train_models/roberta-base --model_type roberta --model_name_or_path roberta-base --train_file ./data/train_separate_questions_parties.json --predict_file ./data/test.json --do_train --do_eval --version_2_with_negative --learning_rate 1e-4 --num_train_epochs 4 --per_gpu_eval_batch_size=40 --per_gpu_train_batch_size=40 --max_seq_length 512 --max_answer_length 128 --doc_stride 128 --save_steps 1000 --n_best_size 20 --overwrite_output_dir --threads 4\n",
    "# --max_answer_length 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b103a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers.data.processors.squad import SquadV2Processor\n",
    "\n",
    "data_dir = './data'\n",
    "train_file = 'train_separate_questions_parties.json'\n",
    "\n",
    "processor = SquadV2Processor()\n",
    "examples = processor.get_train_examples(data_dir, filename=train_file)\n",
    "len(examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe36ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    squad_convert_examples_to_features\n",
    ")\n",
    "output_dir = './train_models/roberta-base'\n",
    "model_name_or_path = 'roberta-base'\n",
    "tokenizer_name = model_name_or_path\n",
    "do_lower_case=False\n",
    "cache_dir=None\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_name,\n",
    "    do_lower_case=do_lower_case,\n",
    "    cache_dir=cache_dir,\n",
    "    use_fast=False,\n",
    ")\n",
    "\n",
    "evaluate=False\n",
    "threads=4\n",
    "max_seq_length=512\n",
    "max_query_length=256\n",
    "doc_stride=256\n",
    "\n",
    "features, dataset = squad_convert_examples_to_features(\n",
    "    examples=examples,\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=max_seq_length,\n",
    "    doc_stride=doc_stride,\n",
    "    max_query_length=max_query_length,\n",
    "    is_training=not evaluate,\n",
    "    return_dataset=\"pt\",\n",
    "    threads=threads,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f353a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "def get_dataset_pos_mask(dataset):\n",
    "    \"\"\"\n",
    "    Returns a list, pos_mask, where pos_mask[i] indicates is True if the ith example in the dataset is positive\n",
    "    (i.e. it contains some text that should be highlighted) and False otherwise.\n",
    "    \"\"\"\n",
    "    pos_mask = []\n",
    "    for i in range(len(dataset)):\n",
    "        ex = dataset[i]\n",
    "        start_pos = ex[3]\n",
    "        end_pos = ex[4]\n",
    "        is_positive = end_pos > start_pos\n",
    "        pos_mask.append(is_positive)\n",
    "    return pos_mask\n",
    "def get_balanced_dataset(dataset):\n",
    "    \"\"\"\n",
    "    returns a new dataset, where positive and negative examples are approximately balanced\n",
    "    \"\"\"\n",
    "    pos_mask = get_dataset_pos_mask(dataset)\n",
    "    neg_mask = [~mask for mask in pos_mask]\n",
    "    npos, nneg = np.sum(pos_mask), np.sum(neg_mask)\n",
    "\n",
    "    neg_keep_frac = npos / nneg  # So that in expectation there will be npos negative examples (--> balanced)\n",
    "    neg_keep_mask = [mask and np.random.random() < neg_keep_frac for mask in neg_mask]\n",
    "\n",
    "    # keep all positive examples and subset of negative examples\n",
    "    keep_mask = [pos_mask[i] or neg_keep_mask[i] for i in range(len(pos_mask))]\n",
    "    keep_indices = [i for i in range(len(keep_mask)) if keep_mask[i]]\n",
    "\n",
    "    subset_dataset = torch.utils.data.Subset(dataset, keep_indices)\n",
    "    return subset_dataset\n",
    "\n",
    "cache_dir = ''\n",
    "model_name_or_path = 'roberta-base'\n",
    "max_seq_length=512\n",
    "subset_cached_features_file = os.path.join(\n",
    "    cache_dir,\n",
    "    \"balanced_subset_cached_{}_{}_{}\".format(\n",
    "        \"dev\" if evaluate else \"train\",\n",
    "        list(filter(None, model_name_or_path.split(\"/\"))).pop(),\n",
    "        str(max_seq_length),\n",
    "    ),\n",
    ")\n",
    "b_dataset = get_balanced_dataset(dataset)\n",
    "torch.save({\"dataset\": b_dataset}, subset_cached_features_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca99cc6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275ebcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -O CUAD_v1.zip https://zenodo.org/record/4595826/files/CUAD_v1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4630fa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUAD_v1.json       full_contract_pdf  label_group_xlsx\n",
    "# CUAD_v1_README.txt full_contract_txt  master_clauses.csv\n",
    "\n",
    "# import zipfile\n",
    "# with zipfile.ZipFile('CUAD_v1.zip') as zfp:\n",
    "#     zfp.extractall('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
